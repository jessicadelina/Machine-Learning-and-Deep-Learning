{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mrq5s9WWYcAV"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOGAR9QHYcAZ"
      },
      "source": [
        "Preparation biasa dilakukan untuk mempersiapkan data sebelum masuk dalam tahap pemodelan. <br>\n",
        "Berikut adalah tahapan yang akan dilalui pada data `SC_HW1_bank_data.csv` sebelum tahap pemodelan :\n",
        "1. Import Library\n",
        "2. Input Dataset\n",
        "3. Preprocessing\n",
        "4. Train-Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUIg363RYcAZ"
      },
      "source": [
        "## Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CWrO8BImYcAa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_wYppbCYcAb"
      },
      "source": [
        "## Input Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bU29IupsYcAb"
      },
      "outputs": [],
      "source": [
        "#Membaca data dan memasukkannya ke dalam bentuk Pandas Dataframe\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/Rietaros/kampus_merdeka/main/SC_HW1_bank_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "V7swrXGTYcAc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eee827e-8f00-474d-9c78-b12c8494afeb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['RowNumber', 'CustomerId', 'Geography', 'Gender', 'Age', 'Tenure',\n",
              "       'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember',\n",
              "       'EstimatedSalary', 'Exited'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "#Jalankan code untuk mengecek nama kolom yang tersedia\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ySBcdpGy4rb3"
      },
      "outputs": [],
      "source": [
        "#Hilangkan kolom yang dirasa tidak relevan dengan model (contoh: ID). None dapat diisi dengan nama-nama kolom yang akan digunakan.\n",
        "#Contoh df = df[['X1','X2', 'Y']].copy()\n",
        "\n",
        "#START CODE\n",
        "df = df[['Geography', 'Gender', 'Age', 'Tenure','Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember','EstimatedSalary', 'Exited']].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAUrcQVIYcAe"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "owVHMXqEYcAe"
      },
      "outputs": [],
      "source": [
        "#Lakukan One-Hot Encoder untuk data categorical, dengan fungsi pandas get_dummies\n",
        "\n",
        "#START CODE\n",
        "df = pd.DataFrame(df)\n",
        "df_encoded = pd.get_dummies(df, columns=['Geography', 'Gender'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zMNWzfUbYcAf"
      },
      "outputs": [],
      "source": [
        "#Pisahkan mana X (feature) dengan Y,\n",
        "#Y adalah kolom \"Exited\"\n",
        "\n",
        "#START CODE\n",
        "X = df_encoded.drop(columns=['Exited'])\n",
        "y = df_encoded['Exited']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XWfdSiCxYcAg"
      },
      "outputs": [],
      "source": [
        "#Lakukan Scaler dan/atau Noermalisasi jika diperlukan\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#START CODE\n",
        "scaler = MinMaxScaler()\n",
        "X_transform = scaler.fit_transform(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "W5u5pH3uYcAg"
      },
      "outputs": [],
      "source": [
        "#Ini digunakan jika dilakukan scaler/Normalisas. Jika tidak, code ini bisa dilewat dan diganti dengan code yang ada di dalam komen\n",
        "X_transform = pd.DataFrame(X_transform, columns = X.columns)\n",
        "#X_transform = X.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Pi0qKQAYcAh"
      },
      "source": [
        "## Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0RDnybGDYcAh"
      },
      "outputs": [],
      "source": [
        "#Split menjadi train dan test dengan test_size 25%\n",
        "#Tidak perlu mengubah code ini\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X_transform,y,test_size = 0.25,random_state = 123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hIL9sbPYcAh"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PPYhjm3YcAi"
      },
      "source": [
        "## Model1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt2iNWWTYcAj"
      },
      "source": [
        "### Soal :\n",
        "Jelaskan secara Singkat Model pertama yang digunakan!\n",
        "\n",
        "Random Forest adalah model ensambel yang terdiri dari beberapa pohon keputusan. Setiap pohon keputusan dibangun secara independen, dan hasil prediksi diambil dengan mengumpulkan hasil dari semua pohon. Random Forest efektif dalam mengatasi overfitting, mampu menangani data berdimensi tinggi, dan dapat digunakan untuk klasifikasi dan regresi."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "UCfQJoeopIJ_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bnqFXuCyYcAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7b0b44f-a326-4244-e106-e0383f1b78fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': None,\n",
              " 'min_samples_leaf': 4,\n",
              " 'min_samples_split': 5,\n",
              " 'n_estimators': 50}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#START CODE\n",
        "model1 = RandomForestClassifier()\n",
        "params = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "#END CODE\n",
        "\n",
        "#Lakukan parameter tuning sesuai hyperparameter yang dibutuhkan\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "grid = GridSearchCV(\n",
        "             estimator= model1,\n",
        "             param_grid= params,\n",
        "             scoring = 'accuracy',\n",
        "             n_jobs = 10, # core cpu yang digunakan\n",
        "             cv = 10 # 3-fold cross validation (artinya kita melakukan iterasi model sebanyak 3 kali)\n",
        "            )\n",
        "\n",
        "grid.fit(X_train,y_train)\n",
        "grid.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1f32JE8kYcAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdd5d756-6204-454b-d367-f8452dc096b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.97      0.92      1983\n",
            "           1       0.78      0.46      0.58       517\n",
            "\n",
            "    accuracy                           0.86      2500\n",
            "   macro avg       0.83      0.71      0.75      2500\n",
            "weighted avg       0.85      0.86      0.85      2500\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1917   66]\n",
            " [ 279  238]]\n",
            "Akurasi: 0.862\n"
          ]
        }
      ],
      "source": [
        "#lakukan evaluasi dengan beberapa maetric di bawah ini\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_pred = grid.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Akurasi:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXuooROd4rb8"
      },
      "source": [
        "## Model2\n",
        "### Soal :\n",
        "Jelaskan secara Singkat Model ke-2 yang digunakan!\n",
        "\n",
        "Support Vector Machine (SVM) adalah model pembelajaran mesin yang digunakan untuk klasifikasi dan regresi. SVM berfokus pada pemisahan dua kelas dengan mencari \"margin\" terbesar antara kedua kelas. SVM dapat menangani data linier dan non-linier dengan menggunakan kernel, seperti kernel radial (RBF) atau kernel polinomial. SVM dikenal dengan kemampuannya dalam menangani data yang tidak terdistribusi secara merata dan memiliki tingkat akurasi yang tinggi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HfJRofJL4rb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bc44c10-b4c0-4a10-b9c1-8311940c3bfc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 10, 'gamma': 1, 'kernel': 'poly'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "#START CODE\n",
        "model2 = SVC()\n",
        "params2 = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': ['scale', 'auto', 0.1, 1]\n",
        "}\n",
        "\n",
        "# Lakukan parameter tuning sesuai hyperparameter yang dibutuhkan\n",
        "grid2 = GridSearchCV(\n",
        "    estimator=model2,\n",
        "    param_grid=params2,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=10,\n",
        "    cv=10\n",
        ")\n",
        "\n",
        "grid2.fit(X_train, y_train)\n",
        "grid2.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GOZ6oeyW4rb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb670a47-9eda-4503-b666-84c285eb4e79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.98      0.92      1983\n",
            "           1       0.82      0.44      0.57       517\n",
            "\n",
            "    accuracy                           0.86      2500\n",
            "   macro avg       0.85      0.71      0.75      2500\n",
            "weighted avg       0.86      0.86      0.85      2500\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1934   49]\n",
            " [ 289  228]]\n",
            "Akurasi: 0.8648\n"
          ]
        }
      ],
      "source": [
        "#lakukan evaluasi\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_pred = grid2.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Akurasi:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poj5B7fF4rb9"
      },
      "source": [
        "## Model3\n",
        "### Soal :\n",
        "Jelaskan secara Singkat Model ke-3 yang digunakan!\n",
        "\n",
        "Logistic Regression (Regresi Logistik) adalah model statistik yang digunakan untuk masalah klasifikasi. Meskipun namanya mengandung kata \"regresi,\" ini adalah algoritma klasifikasi. Logistic Regression memodelkan probabilitas bahwa sampel termasuk dalam suatu kelas dengan menggunakan fungsi logistik. Model ini cocok untuk tugas klasifikasi biner dan multikelas, dan relatif mudah untuk diinterpretasi. Ini adalah model linier yang cocok untuk pemisahan linier antara kelas, meskipun ekstensi seperti regresi logistik multinomial dapat digunakan untuk masalah multikelas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "O6riqEA74rb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13ae82df-42a2-47a9-d426-85db0b76e6b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "30 fits failed out of a total of 60.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "30 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.81026667        nan 0.80933333        nan 0.8084    ]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 0.1, 'penalty': 'l2'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "#START CODE\n",
        "model3 = LogisticRegression()\n",
        "params3 = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "# Lakukan parameter tuning sesuai hyperparameter yang dibutuhkan\n",
        "grid3 = GridSearchCV(\n",
        "    estimator=model3,\n",
        "    param_grid=params3,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=10,\n",
        "    cv=10\n",
        ")\n",
        "\n",
        "grid3.fit(X_train, y_train)\n",
        "grid3.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4D60gsBj4rb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f12c0a01-27fd-421d-d12c-8676e7ae1411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.98      0.89      1983\n",
            "           1       0.72      0.15      0.25       517\n",
            "\n",
            "    accuracy                           0.81      2500\n",
            "   macro avg       0.77      0.57      0.57      2500\n",
            "weighted avg       0.80      0.81      0.76      2500\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1953   30]\n",
            " [ 439   78]]\n",
            "Akurasi: 0.8124\n"
          ]
        }
      ],
      "source": [
        "#lakukan evaluasi\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_pred = grid3.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Akurasi:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Blfl1F2M4rb-"
      },
      "source": [
        "## Tarik Kesimpulan Model Mana yang terbaik beserta alasannya"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kesimpulannya model terbaik untuk mendapat akurasi tertinggi adalah SVM dengan akurasi 86,4%. Alasannya ada 4 yaitu\n",
        "1. Kemampuan untuk Menangani Data Non-linear: SVM memiliki kemampuan bawaan untuk menangani pemisahan kelas yang kompleks, terutama dengan menggunakan kernel seperti 'rbf' atau 'poly'. Ini memungkinkan SVM untuk berperforma baik pada dataset yang tidak memiliki pemisahan linier yang jelas.\n",
        "\n",
        "2. Optimasi Terbaik: SVM berusaha untuk menemukan margin maksimum antara kelas yang memungkinkan model memisahkan data dengan baik. Oleh karena itu, SVM biasanya memberikan pemisahan kelas yang lebih baik dibandingkan dengan beberapa model lainnya.\n",
        "\n",
        "3. Pengendalian Overfitting: SVM memiliki parameter seperti C yang memungkinkan pengendalian ketat terhadap overfitting. Dengan penalaian yang tepat terhadap parameter-parameter ini, Anda dapat menghindari overfitting pada model SVM Anda.\n",
        "\n",
        "4. Dukungan Vektor: SVM hanya bergantung pada sejumlah kecil \"dukungan vektor\" untuk membuat keputusan klasifikasi. Hal ini memungkinkan SVM untuk lebih tahan terhadap outliers dan noise dalam data."
      ],
      "metadata": {
        "id": "nZVGdV8FNo07"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "toc-autonumbering": true,
    "toc-showcode": false,
    "toc-showmarkdowntxt": false
  },
  "nbformat": 4,
  "nbformat_minor": 0
}